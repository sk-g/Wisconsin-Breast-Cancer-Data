{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum accuracy using Logistic Regression = 96.4912 with C = 6.250000\n",
      "Time taken for LogReg = 0.03 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD3CAYAAAAUl4NyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x238a5737860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'nn_acc' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fa542cc2c944>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bc.py\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36mcall_function\u001b[1;34m(x)\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'nn_acc' referenced before assignment"
     ]
    }
   ],
   "source": [
    "exec(open(\"bc.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 50\n",
      "Training Accuracy: 92.0879120879\n",
      "Test Accuracy: 92.1052631579\n",
      "Time taken: 52.9314\n",
      "\n",
      " 51\n",
      "Training Accuracy: 92.967032967\n",
      "Test Accuracy: 90.350877193\n",
      "Time taken: 53.5699\n",
      "\n",
      " 52\n",
      "Training Accuracy: 92.5274725275\n",
      "Test Accuracy: 92.9824561404\n",
      "Time taken: 53.8288\n",
      "\n",
      " 53\n",
      "Training Accuracy: 92.7472527473\n",
      "Test Accuracy: 88.5964912281\n",
      "Time taken: 52.8479\n",
      "\n",
      " 54\n",
      "Training Accuracy: 94.2857142857\n",
      "Test Accuracy: 93.8596491228\n",
      "Time taken: 53.8525\n",
      "\n",
      " 55\n",
      "Training Accuracy: 92.0879120879\n",
      "Test Accuracy: 91.2280701754\n",
      "Time taken: 53.9910\n",
      "\n",
      " 56\n",
      "Training Accuracy: 92.5274725275\n",
      "Test Accuracy: 94.7368421053\n",
      "Time taken: 55.1604\n",
      "\n",
      " 57\n",
      "Training Accuracy: 92.0879120879\n",
      "Test Accuracy: 92.9824561404\n",
      "Time taken: 55.4965\n",
      "\n",
      " 58\n",
      "Training Accuracy: 92.5274725275\n",
      "Test Accuracy: 88.5964912281\n",
      "Time taken: 55.4741\n",
      "\n",
      " 59\n",
      "Training Accuracy: 91.2087912088\n",
      "Test Accuracy: 96.4912280702\n",
      "Time taken: 55.7161\n",
      "\n",
      " 60\n",
      "Training Accuracy: 92.0879120879\n",
      "Test Accuracy: 90.350877193\n",
      "Time taken: 57.3029\n",
      "\n",
      " 61\n",
      "Training Accuracy: 93.1868131868\n",
      "Test Accuracy: 88.5964912281\n",
      "Time taken: 60.0925\n",
      "\n",
      " 62\n",
      "Training Accuracy: 92.0879120879\n",
      "Test Accuracy: 90.350877193\n",
      "Time taken: 63.0634\n",
      "\n",
      " 63\n",
      "Training Accuracy: 93.8461538462\n",
      "Test Accuracy: 90.350877193\n",
      "Time taken: 62.9550\n",
      "\n",
      " 64\n",
      "Training Accuracy: 92.3076923077\n",
      "Test Accuracy: 92.1052631579\n",
      "Time taken: 63.4469\n",
      "\n",
      " 65\n",
      "Training Accuracy: 92.0879120879\n",
      "Test Accuracy: 93.8596491228\n",
      "Time taken: 63.2782\n",
      "\n",
      " 66\n",
      "Training Accuracy: 92.3076923077\n",
      "Test Accuracy: 92.9824561404\n",
      "Time taken: 71.4536\n",
      "\n",
      " 67\n",
      "Training Accuracy: 92.0879120879\n",
      "Test Accuracy: 92.9824561404\n",
      "Time taken: 66.1629\n",
      "\n",
      " 68\n",
      "Training Accuracy: 92.0879120879\n",
      "Test Accuracy: 92.9824561404\n",
      "Time taken: 56.1329\n",
      "\n",
      " 69\n",
      "Training Accuracy: 92.3076923077\n",
      "Test Accuracy: 93.8596491228\n",
      "Time taken: 59.1077\n",
      "\n",
      " 70\n",
      "Training Accuracy: 91.8681318681\n",
      "Test Accuracy: 91.2280701754\n",
      "Time taken: 66.7385\n",
      "\n",
      " 71\n",
      "Training Accuracy: 94.0659340659\n",
      "Test Accuracy: 90.350877193\n",
      "Time taken: 65.6040\n",
      "\n",
      " 72\n",
      "Training Accuracy: 92.0879120879\n",
      "Test Accuracy: 88.5964912281\n",
      "Time taken: 59.9808\n",
      "\n",
      " 73\n",
      "Training Accuracy: 92.0879120879\n",
      "Test Accuracy: 89.4736842105\n",
      "Time taken: 58.9389\n",
      "\n",
      " 74\n",
      "Training Accuracy: 92.0879120879\n",
      "Test Accuracy: 96.4912280702\n",
      "Time taken: 59.2381\n",
      "\n",
      " 75\n",
      "Training Accuracy: 92.5274725275\n",
      "Test Accuracy: 88.5964912281\n",
      "Time taken: 60.5453\n",
      "\n",
      " 76\n",
      "Training Accuracy: 92.3076923077\n",
      "Test Accuracy: 88.5964912281\n",
      "Time taken: 60.0567\n",
      "\n",
      " 77\n",
      "Training Accuracy: 91.6483516484\n",
      "Test Accuracy: 98.2456140351\n",
      "Time taken: 61.3396\n",
      "\n",
      " 78\n",
      "Training Accuracy: 91.2087912088\n",
      "Test Accuracy: 95.6140350877\n",
      "Time taken: 61.5685\n",
      "\n",
      " 79\n",
      "Training Accuracy: 92.3076923077\n",
      "Test Accuracy: 92.9824561404\n",
      "Time taken: 61.9150\n",
      "\n",
      " 80\n",
      "Training Accuracy: 92.7472527473\n",
      "Test Accuracy: 93.8596491228\n",
      "Time taken: 62.9898\n",
      "\n",
      " 81\n",
      "Training Accuracy: 91.4285714286\n",
      "Test Accuracy: 93.8596491228\n",
      "Time taken: 64.1778\n",
      "\n",
      " 82\n",
      "Training Accuracy: 91.6483516484\n",
      "Test Accuracy: 93.8596491228\n",
      "Time taken: 64.9031\n",
      "\n",
      " 83\n",
      "Training Accuracy: 91.4285714286\n",
      "Test Accuracy: 92.1052631579\n",
      "Time taken: 66.4249\n",
      "\n",
      " 84\n",
      "Training Accuracy: 91.8681318681\n",
      "Test Accuracy: 92.1052631579\n",
      "Time taken: 65.7828\n",
      "\n",
      " 85\n",
      "Training Accuracy: 91.8681318681\n",
      "Test Accuracy: 92.9824561404\n",
      "Time taken: 66.0446\n",
      "\n",
      " 86\n",
      "Training Accuracy: 92.0879120879\n",
      "Test Accuracy: 95.6140350877\n",
      "Time taken: 68.0125\n",
      "\n",
      " 87\n",
      "Training Accuracy: 91.8681318681\n",
      "Test Accuracy: 93.8596491228\n",
      "Time taken: 68.0353\n",
      "\n",
      " 88\n",
      "Training Accuracy: 94.7252747253\n",
      "Test Accuracy: 92.9824561404\n",
      "Time taken: 68.5389\n",
      "\n",
      " 89\n",
      "Training Accuracy: 92.7472527473\n",
      "Test Accuracy: 87.7192982456\n",
      "Time taken: 68.7128\n",
      "\n",
      " 90\n",
      "Training Accuracy: 92.5274725275\n",
      "Test Accuracy: 89.4736842105\n",
      "Time taken: 69.5975\n",
      "\n",
      " 91\n",
      "Training Accuracy: 92.3076923077\n",
      "Test Accuracy: 92.1052631579\n",
      "Time taken: 70.3470\n",
      "\n",
      " 92\n",
      "Training Accuracy: 95.3846153846\n",
      "Test Accuracy: 92.1052631579\n",
      "Time taken: 75.6968\n",
      "\n",
      " 93\n",
      "Training Accuracy: 91.8681318681\n",
      "Test Accuracy: 92.9824561404\n",
      "Time taken: 76.4533\n",
      "\n",
      " 94\n",
      "Training Accuracy: 92.3076923077\n",
      "Test Accuracy: 92.9824561404\n",
      "Time taken: 77.7673\n",
      "\n",
      " 95\n",
      "Training Accuracy: 87.6923076923\n",
      "Test Accuracy: 83.3333333333\n",
      "Time taken: 73.4024\n",
      "\n",
      " 96\n",
      "Training Accuracy: 94.5054945055\n",
      "Test Accuracy: 91.2280701754\n",
      "Time taken: 73.6163\n",
      "\n",
      " 97\n",
      "Training Accuracy: 87.9120879121\n",
      "Test Accuracy: 83.3333333333\n",
      "Time taken: 79.3389\n",
      "\n",
      " 98\n",
      "Training Accuracy: 93.6263736264\n",
      "Test Accuracy: 90.350877193\n",
      "Time taken: 80.7494\n",
      "\n",
      " 99\n",
      "Training Accuracy: 92.7472527473\n",
      "Test Accuracy: 89.4736842105\n",
      "Time taken: 80.7176\n",
      "Time taken = 3203.5878\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEFCAYAAAAPCDf9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x238a56384e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693160\n",
      "Cost after iteration 1000: 0.641446\n",
      "Cost after iteration 2000: 0.431946\n",
      "Cost after iteration 3000: 0.375372\n",
      "Cost after iteration 4000: 0.341437\n",
      "Cost after iteration 5000: 0.319219\n",
      "Cost after iteration 6000: 0.298024\n",
      "Cost after iteration 7000: 0.283739\n",
      "Cost after iteration 8000: 0.271551\n",
      "Cost after iteration 9000: 0.259631\n",
      "Cost after iteration 10000: 0.248966\n",
      "Cost after iteration 11000: 0.245556\n",
      "Cost after iteration 12000: 0.275174\n",
      "Cost after iteration 13000: 0.202904\n",
      "Cost after iteration 14000: 0.209403\n",
      "Training Accuracy: 92.3076923077\n",
      "Test Accuracy: 93.8596491228\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAETCAYAAAA/NdFSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x238a56e07f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum accuracy using Logistic Regression = 99.1228 with C = 781.250000\n",
      "Time taken for LogReg = 0.04 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD6CAYAAACoCZCsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlFJpShOAUkqlqf8P3BbPWjn4sMwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x238a5797ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SVM with  C = 0.010000 \n",
      "Running SVM with  C = 0.020000 \n",
      "Running SVM with  C = 0.040000 \n",
      "Running SVM with  C = 0.080000 \n",
      "Running SVM with  C = 0.160000 \n",
      "Running SVM with  C = 0.320000 \n",
      "Running SVM with  C = 0.640000 \n",
      "Running SVM with  C = 1.280000 \n",
      "Running SVM with  C = 2.560000 \n",
      "Running SVM with  C = 5.120000 \n",
      "Best Accuracy: 96.491228 with C= 0.3200 using rbf kernel\n",
      "Average time taken for SVM = 14.5047 seconds\n",
      "\n",
      "Accuracy using SVM with  rbf : 96.4912280702\n",
      "Time taken for  rbf  = 145.0489 seconds\n",
      "Running SVM with  C = 0.010000 \n",
      "Running SVM with  C = 0.020000 \n",
      "Running SVM with  C = 0.040000 \n",
      "Running SVM with  C = 0.080000 \n",
      "Running SVM with  C = 0.160000 \n",
      "Running SVM with  C = 0.320000 \n",
      "Running SVM with  C = 0.640000 \n",
      "Running SVM with  C = 1.280000 \n",
      "Running SVM with  C = 2.560000 \n",
      "Running SVM with  C = 5.120000 \n",
      "Best Accuracy: 95.614035 with C= 2.5600 using linear kernel\n",
      "Average time taken for SVM = 15.8047 seconds\n",
      "\n",
      "Accuracy using SVM with  linear : 95.6140350877\n",
      "Time taken for  linear  = 158.0488 seconds\n",
      "Running SVM with  C = 0.010000 \n",
      "Running SVM with  C = 0.020000 \n",
      "Running SVM with  C = 0.040000 \n",
      "Running SVM with  C = 0.080000 \n",
      "Running SVM with  C = 0.160000 \n",
      "Running SVM with  C = 0.320000 \n",
      "Running SVM with  C = 0.640000 \n",
      "Running SVM with  C = 1.280000 \n",
      "Running SVM with  C = 2.560000 \n",
      "Running SVM with  C = 5.120000 \n",
      "Best Accuracy: 97.368421 with C= 0.0200 using poly kernel\n",
      "Average time taken for SVM = 17.7462 seconds\n",
      "\n",
      "Accuracy using SVM with  poly : 97.3684210526\n",
      "Time taken for  poly  = 177.4646 seconds\n",
      "Running SVM with  C = 0.010000 \n",
      "Running SVM with  C = 0.020000 \n",
      "Running SVM with  C = 0.040000 \n",
      "Running SVM with  C = 0.080000 \n",
      "Running SVM with  C = 0.160000 \n",
      "Running SVM with  C = 0.320000 \n",
      "Running SVM with  C = 0.640000 \n",
      "Running SVM with  C = 1.280000 \n",
      "Running SVM with  C = 2.560000 \n",
      "Running SVM with  C = 5.120000 \n",
      "Best Accuracy: 60.526316 with C= 0.0100 using sigmoid kernel\n",
      "Average time taken for SVM = 11.1544 seconds\n",
      "\n",
      "Accuracy using SVM with  sigmoid : 60.5263157895\n",
      "Time taken for  sigmoid  = 111.5459 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings,math\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import operator,time,sys; import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn import linear_model,metrics\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV,train_test_split,KFold, cross_val_score\n",
    "import sklearn,matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report\n",
    "#from scipy.optimize import fmin_bfgs as bfgs\n",
    "from sklearn.metrics import log_loss\n",
    "#%matplotlib inline\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "def load(str):\n",
    "\n",
    "\tdf = pd.read_csv(str, header = 0)\n",
    "\tx = df.ix[:,df.columns!='diagnosis']\n",
    "\ty = df.ix[:,df.columns=='diagnosis']\n",
    "\t#print(y)\n",
    "\ty = y['diagnosis'].map({'M':1,'B':0})\n",
    "\t\n",
    "\tx = x.drop(['id','Unnamed: 32','area_mean','perimeter_mean','concavity_mean','concave points_mean','area_worst','perimeter_worst',\n",
    "\t\t'concave points_worst','concavity_worst','area_se','perimeter_se'],axis = 1)\n",
    "\tfeatures = []\n",
    "\tfor i in x:\n",
    "\t\tfeatures.append(i)\n",
    "\tframes = [x,y]\n",
    "\ttotal = pd.concat(frames,axis = 1)\n",
    "\t#print(total)\n",
    "\t#total.info()\n",
    "\treturn total, features\n",
    "\n",
    "def report(grid_scores , n_top = 3):\n",
    "    top_scores = sorted(grid_scores, key = operator.itemgetter(1), reverse= True)[:n_top]\n",
    "\n",
    "def gmm(x,features):\n",
    "\tdel features[-1]\n",
    "\ttrain, test = train_test_split(x, test_size = 0.2)\n",
    "\ttrain_x,test_x = train[features],test[features]\n",
    "\ttrain_y, test_y = train.diagnosis, test.diagnosis\n",
    "\tstart = time.time()\n",
    "\tx_all = np.r_[train_x,test_x]\n",
    "\tlowest_bic = np.infty\n",
    "\tbic = []\n",
    "\tn_components_range = range(1,7)\n",
    "\n",
    "\tcv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "\tfor i in cv_types:\n",
    "\t\tfor j in n_components_range:\n",
    "\t\t\tgmm = GMM(n_components= j, covariance_type = i,min_covar = 0.0001)\n",
    "\n",
    "\t\t\tgmm.fit(x_all)\n",
    "\t\t\tbic.append(gmm.aic(x_all))\n",
    "\t\t\tif bic[-1] < lowest_bic:\n",
    "\t\t\t\tlowest_bic = bic[-1]\n",
    "\t\t\t\tbest_gmm = gmm\n",
    "\tg = best_gmm\n",
    "\tg.fit(x_all)\n",
    "\n",
    "\tx=g.predict_proba(train_x)\n",
    "\n",
    "\tclf = RandomForestClassifier(n_estimators=1500, criterion='entropy', max_depth=15, min_samples_split = 2,min_samples_leaf=3, max_features='auto',\n",
    "\t n_jobs=-1,random_state=343)\n",
    "\tparam_grid = dict()\n",
    "\n",
    "\tgrid_search = GridSearchCV(clf, param_grid=param_grid, scoring='accuracy', cv = 5).fit(x,train_y)\n",
    "\t#print(grid_search.best_estimator_)\n",
    "\treport(grid_search.cv_results_)\n",
    "\tsvc = grid_search.best_estimator_.fit(x,train_y)\n",
    "\t###################\n",
    "\tgrid_search.best_estimator_.score(x, train_y)\n",
    "\tscores = cross_val_score(svc, x, train_y, cv=5, scoring='accuracy')\n",
    "\t#print(scores.mean(), scores.min())\n",
    "\t#print(scores)\n",
    "\tx_t = g.predict_proba(test_x)\n",
    "\n",
    "\ty_pred = grid_search.best_estimator_.predict(x_t)\n",
    "\tend = time.time()\n",
    "\tprint(\"Time taken for RandomForestClassifier with GMM = %.2f seconds\"%(end-start))\n",
    "\t#print(\"Accuracy using RandomForestClassifier with GMM = %.3f\"%(metrics.accuracy_score(y_pred,test_y)*100))\n",
    "\treturn(metrics.accuracy_score(y_pred,test_y)*100)\n",
    "\n",
    "def RandomForests(x,features):\n",
    "\t#RandomForests\n",
    "\tdel features[-1]\n",
    "\ttrain, test = train_test_split(x, test_size = 0.2)\n",
    "\ttrain_x,test_x = train[features],test[features]\n",
    "\ttrain_y, test_y = train.diagnosis, test.diagnosis\n",
    "\tstart = time.time()\n",
    "\tclf = RandomForestClassifier(n_estimators = 1000, max_features = 'auto', criterion = 'entropy',random_state = 30, min_samples_leaf = 5, n_jobs = 2)\n",
    "\tclf.fit(train_x,train_y)\n",
    "\tend = time.time()\n",
    "\ty_pred = clf.predict(test_x)\n",
    "\tacc_2 = metrics.accuracy_score(y_pred,test_y)\n",
    "\tprint(\"\\nTime taken for Random Forest Classifier = %.4f seconds\"%(end-start))\n",
    "\n",
    "\n",
    "\treturn acc_2*100\n",
    "\n",
    "def KNN():\n",
    "\t#K-Nearest Neighbors\n",
    "\tpass\n",
    "\n",
    "def LogReg(x, features):\n",
    "\t#Logistic Regression\n",
    "\tdel features[-1]\n",
    "\ttrain, test = train_test_split(x,test_size = 0.2) # 5 fold CV\n",
    "\ttrain_x, test_x = train[features], test[features]\n",
    "\ttrain_y, test_y = train.diagnosis,test.diagnosis\n",
    "\tstart = time.time()\n",
    "\tc_p = []\n",
    "\tacc_dict = {}\n",
    "\tt= 0.01\n",
    "\ttraining_accuracy = []\n",
    "\ttesting_accuracy = []\n",
    "\twhile t<=pow(10,4):\n",
    "\t\tc_p.append(t)\n",
    "\t\tt*=5\n",
    "\tfor c in c_p:\n",
    "\t\t#print(\"Running Log Reg with %.6f\"%(c))\n",
    "\t\tclf = LogisticRegression(C = c, penalty = 'l2')\n",
    "\t\t# training model using given data\n",
    "\t\tclf.fit(train_x,train_y)\n",
    "\n",
    "\t\t#training set accuracy\n",
    "\t\ty_pred_train = clf.predict(train_x)\n",
    "\t\tacc_train = metrics.accuracy_score(y_pred_train,train_y)\n",
    "\t\ttraining_accuracy.append(acc_train)\n",
    "\n",
    "\t\t# test set accuracy\n",
    "\t\ty_pred_test = clf.predict(test_x)\n",
    "\t\tacc_test = metrics.accuracy_score(y_pred_test,test_y)\n",
    "\t\ttesting_accuracy.append(acc_test)\n",
    "\t\tacc_dict[c] = acc_test\n",
    "\t\t#print(\"Accuracy = \",acc_test)\n",
    "\tend = time.time()\n",
    "\tprint(\"\\nMaximum accuracy using Logistic Regression = %.4f with C = %.6f\"%( max(acc_dict.items(),key = operator.itemgetter(1))[1]*100,\n",
    "\t\tmax(acc_dict.items(), key = operator.itemgetter(1))[0]))\n",
    "\tprint(\"Time taken for LogReg = %.2f seconds\"%(end-start))\n",
    "\t#print(c_p) \n",
    "\tplt.plot(c_p,training_accuracy, label = 'Training Accuracy')\n",
    "\tplt.plot(c_p,testing_accuracy, label = 'Testing Accuracy')\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "def ADB():\n",
    "\t#adaBoost\n",
    "\tpass\n",
    "\n",
    "def SVM(x,features,kernel = 'rbf'):\n",
    "\tdel features[-1]\n",
    "\t#for pos,val in enumerate(features):\tprint(pos,val)\n",
    "\ttrain, test = train_test_split(x, test_size = 0.2)\n",
    "\ttrain_x,test_x = train[features],test[features]\n",
    "\ttrain_y, test_y = train.diagnosis, test.diagnosis\n",
    "\t#for pos,val in enumerate(train_x):\tprint(pos,val)\n",
    "\t#print(train_x.shape)\n",
    "\t#print(test_x.shape)\n",
    "\tkernel = str(kernel)\n",
    "\tstart = time.time()\n",
    "\tc_param_range = []\n",
    "\tt=0.01\n",
    "\twhile t<=pow(10,1):\n",
    "\t\tc_param_range.append(t)\n",
    "\t\tt*=2\n",
    "\n",
    "\n",
    "\tresults_table_svm = pd.DataFrame(index = range(len(c_param_range),2), columns = ['C_parameter','Accuracy'])\n",
    "\tresults_table_svm['C_parameter'] = c_param_range\n",
    "\tj = 0\n",
    "\t\n",
    "\tacc_dict_svm={}\n",
    "\tfor c_param in c_param_range:\n",
    "\t\tprint(\"Running SVM with  C = %f \"%(c_param))\n",
    "\t\t\t\n",
    "\t\tclf = BaggingClassifier(SVC(C = c_param, kernel = kernel),n_jobs=-1)\n",
    "\n",
    "\t\tclf.fit(train_x,train_y)\n",
    "\n",
    "\t\ty_pred = clf.predict(test_x)\n",
    "\n",
    "\t\tacc = metrics.accuracy_score(y_pred,test_y)\n",
    "\n",
    "\n",
    "\t\tacc_dict_svm[c_param]=acc\n",
    "\t\tresults_table_svm.ix[j,'Accuracy'] = acc\n",
    "\t\tj += 1\n",
    "\n",
    "\n",
    "\tbest_c_svm = results_table_svm.loc[results_table_svm['Accuracy'].idxmax()]['C_parameter']\n",
    "\tprint(\"Best Accuracy: %f with C= %.4f using %s kernel\"%(max(acc_dict_svm.items(),key = operator.itemgetter(1))[1]*100,\n",
    "\t\tmax(acc_dict_svm.items(),key = operator.itemgetter(1))[0],kernel))\n",
    "\tend = time.time()\n",
    "\tprint(\"Average time taken for SVM = %.4f seconds\"%((end-start)/len(c_param_range)))\n",
    "\treturn acc_dict_svm[best_c_svm]\n",
    "\n",
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Implements the sigmoid activation in numpy\n",
    "    \n",
    "    Arguments:\n",
    "    Z -- numpy array of any shape\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of sigmoid(z), same shape as Z\n",
    "    cache -- returns Z as well, useful during backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Implement the RELU function.\n",
    "\n",
    "    Arguments:\n",
    "    Z -- Output of the linear layer, of any shape\n",
    "\n",
    "    Returns:\n",
    "    A -- Post-activation parameter, of the same shape as Z\n",
    "    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    #assert(A.shape == Z.shape)\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "\n",
    "    np.random.seed(13456)\n",
    "    \n",
    "\n",
    "    W1 = np.random.randn(n_h,n_x) * 0.01 /np.sqrt(n_h)\n",
    "    b1 = np.random.randn(n_h,1)*0.01/np.sqrt(n_h)\n",
    "    W2 = np.random.randn(n_y,n_h) * 0.01 /np.sqrt(n_y)\n",
    "    b2 = np.random.randn(n_y,1)*0.01 /np.sqrt(n_y)\n",
    "   \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def initialize_parameters_deep(layer_dims):\n",
    "\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1]) * 0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "  \n",
    "    return parameters\n",
    "\n",
    "def linear_forward(A, W, b):\n",
    "\n",
    "    Z = np.dot(W,A) + b\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache\n",
    "\n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "\n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache\n",
    "\n",
    "def L_model_forward(X, parameters):\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)],parameters['b' + str(l)],activation='relu')\n",
    "        \n",
    "        caches.append(cache)\n",
    "\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)],parameters['b' + str(L)],activation='sigmoid')\n",
    "    caches.append(cache)    \n",
    "    #assert(AL.shape == (1,X.shape[1]))\n",
    "            \n",
    "    return AL, caches\n",
    "\n",
    "def compute_cost(AL, Y):\n",
    "\n",
    "    m = Y.shape[1]\n",
    "    cost = (-1 / m) * np.sum(np.dot(Y, np.log(AL).T) + np.dot(1 - Y, np.log(1 - AL).T))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    #assert(cost.shape == ())\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def linear_backward(dZ, cache):\n",
    "\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = np.dot(dZ, cache[0].T) / m\n",
    "    db = (np.sum(dZ,axis = 1, keepdims = True)) / m\n",
    "    #print(db.shape)\n",
    "    dA_prev = np.dot(cache[1].T,dZ)\n",
    "\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    #assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "\n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    #assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "\n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "    dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def L_model_backward(AL, Y, caches):\n",
    "\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    current_cache = caches[-1]\n",
    "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL,\n",
    "                                                                                                  current_cache,\n",
    "                                                                                                  \"sigmoid\")\n",
    "\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA{}\".format(l + 2)],\n",
    "                                                                    current_cache,\n",
    "                                                                    \"relu\")\n",
    "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "\n",
    "    L = len(parameters) // 2\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W{}\".format(l + 1)] - learning_rate * grads[\"dW{}\".format(l + 1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b{}\".format(l + 1)] - learning_rate * grads[\"db{}\".format(l + 1)]\n",
    "    return parameters\n",
    "\n",
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  L-layer neural network.\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    print(\"Test Accuracy: \"  + str(np.sum((p == y)*100/m)))\n",
    "        \n",
    "    return np.sum((p == y)*100/m)\n",
    "\n",
    "def two_layer_model(data, features,n_h, learning_rate = 0.015, num_iterations = 30000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Implements a two-layer neural network: LINEAR->RELU->LINEAR->SIGMOID.\n",
    "    \n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    del features[-1]\n",
    "    train, test = train_test_split(data, test_size = 0.2)\n",
    "    train_x,test_x = train[features],test[features]\n",
    "    train_y, test_y = train.diagnosis.values.reshape((train.diagnosis.shape[0],1)),test.diagnosis.values.reshape((test.diagnosis.shape[0],1))\n",
    "    train_x,test_x = train_x.T,test_x.T\n",
    "    train_y = train_y.T\n",
    "    test_y = test_y.T\n",
    "    np.random.seed(1)\n",
    "    grads = {}\n",
    "    costs = []                              # to keep track of the cost\n",
    "    m = train_x.shape[1]                           # number of examples\n",
    "    n_x = train_x.shape[0]\n",
    "    n_h = n_h\n",
    "    n_y = train_y.shape[0]\n",
    "    \n",
    "    # Initialize parameters dictionary, by calling one of the functions you'd previously implemented\n",
    "    ### START CODE HERE ### ( 1 line of code)\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Get W1, b1, W2 and b2 from the dictionary parameters.\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: LINEAR -> RELU -> LINEAR -> SIGMOID. Inputs: \"X, W1, b1\". Output: \"A1, cache1, A2, cache2\".\n",
    "        ### START CODE HERE ### ( 2 lines of code)\n",
    "        A1, cache1 = linear_activation_forward(train_x, W1, b1, 'relu')\n",
    "        A2, cache2 = linear_activation_forward(A1, W2, b2, 'sigmoid')\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Compute cost\n",
    "        ### START CODE HERE ### ( 1 line of code)\n",
    "        cost = compute_cost(A2, train_y)\n",
    "        ### END CODE HERE ###\n",
    "        if cost <= 0.1:\n",
    "        \tbreak\n",
    "        # Initializing backward propagation\n",
    "        dA2 = - (np.divide(train_y, A2) - np.divide(1 - train_y, 1 - A2))\n",
    "        \n",
    "        # Backward propagation. Inputs: \"dA2, cache2, cache1\". Outputs: \"dA1, dW2, db2; also dA0 (not used), dW1, db1\".\n",
    "        ### START CODE HERE ### ( 2 lines of code)\n",
    "        dA1, dW2, db2 = linear_activation_backward(dA2, cache2, 'sigmoid')\n",
    "        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, 'relu')\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Set grads['dWl'] to dW1, grads['db1'] to db1, grads['dW2'] to dW2, grads['db2'] to db2\n",
    "        grads['dW1'] = dW1\n",
    "        grads['db1'] = db1\n",
    "        grads['dW2'] = dW2\n",
    "        grads['db2'] = db2\n",
    "        \n",
    "        # Update parameters.\n",
    "        ### START CODE HERE ### (approx. 1 line of code)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Retrieve W1, b1, W2, b2 from parameters\n",
    "        W1 = parameters[\"W1\"]\n",
    "        b1 = parameters[\"b1\"]\n",
    "        W2 = parameters[\"W2\"]\n",
    "        b2 = parameters[\"b2\"]\n",
    "        \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            costs.append(cost)\n",
    "       \n",
    "\n",
    "    \n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = L_model_forward(train_x, parameters)\n",
    "\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    #print(p.shape)\n",
    "    #print('\\n',test_y.shape)\n",
    "    #print results\n",
    "    #print (\"predictions: \" + str(p))\n",
    "    #print (\"true labels: \" + str(y))\n",
    "    print(\"Training Accuracy: \"  + str(np.sum((p == train_y)*100)/455))\n",
    "    a = predict(test_x,test_y,parameters)\n",
    "    end = time.time()\n",
    "    print(\"Time taken: %.4f\"%(end-start))\n",
    "    return a\n",
    "    ###### plot the cost   #######\n",
    "\"\"\"\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "\t\n",
    "\n",
    "def L_layer_model(data, features, layers_dims, learning_rate = 0.015, num_iterations = 5000, print_cost=False):#lr was 0.009\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    del features[-1]\n",
    "    train, test = train_test_split(data, test_size = 0.2)\n",
    "    train_x,test_x = train[features],test[features]\n",
    "    train_y, test_y = train.diagnosis.values.reshape((train.diagnosis.shape[0],1)),test.diagnosis.values.reshape((test.diagnosis.shape[0],1))\n",
    "    train_x,test_x = train_x.T,test_x.T\n",
    "    train_y = train_y.T\n",
    "    test_y = test_y.T\n",
    "    np.random.seed(11)\n",
    "    costs = []                         # keep track of cost\n",
    "    m = train_x.shape[1]\n",
    "    # Parameters initialization.\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        AL, caches = L_model_forward(train_x, parameters)\n",
    "\n",
    "        # Compute cost.\n",
    "\n",
    "        cost = compute_cost(AL, train_y)\n",
    "        if cost < 0.1:\n",
    "        \tpass\n",
    "    \n",
    "        # Backward propagation.\n",
    "\n",
    "        grads = L_model_backward(AL, train_y, caches)\n",
    "\n",
    " \n",
    "        # Update parameters.\n",
    "\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "              \n",
    "\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            costs.append(cost)\n",
    "        p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "        probas, caches = L_model_forward(train_x, parameters)\n",
    "\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "        \tp[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "\n",
    "    print(\"Training Accuracy: \"  + str(np.sum((p == train_y) * 100 )/455))\n",
    "    predict(test_x,test_y,parameters)\n",
    "    end = time.time()\n",
    "    #print(\"Time taken: %.4f\"%(end-start))\n",
    "    ###### plot the cost   #######\n",
    "\n",
    "\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters\n",
    "def NeuralNetwork(x,features):\n",
    "\t# Neural Network with one hidden layer\n",
    "\t# Will try and work with more hidden layers\n",
    "\t# Optimization of hyperparameters for one hidden layer NN supported\n",
    "\t# WORK IN PROGRESS\n",
    "\tdel features[-1]\n",
    "\ttrain, test = train_test_split(x, test_size = 0.2)\n",
    "\ttrain_x,test_x = train[features],test[features]\n",
    "\ttrain_y, test_y = train.diagnosis.values.reshape((train.diagnosis.shape[0],1)),test.diagnosis.values.reshape((test.diagnosis.shape[0],1))\n",
    "\ttrain_y = train_y.T\n",
    "\ttest_y = test_y.T\n",
    "\t\"\"\"\n",
    "\t# Checking dimensions\n",
    "\tprint(test_y, '\\n',test.diagnosis)\n",
    "\tprint(\"shape of train_x = \",train_x.shape)\n",
    "\tprint(\"shape of test_x = \",test_x.shape)\n",
    "\tprint(\"shape of train_y = \",train_y.shape)\n",
    "\tprint(\"shape of test_y = \",test_y.shape)\n",
    "\t\"\"\"\n",
    "\t\n",
    "\t# DEFINING PARAMETERS \n",
    "\tn_h = 5 # number of hidden units\n",
    "\t\n",
    "\t# layer 1 (input layer)\n",
    "\n",
    "\tw1 = np.random.randn(n_h,train_x.shape[1])*0.01/np.sqrt(train_x.shape[0])\n",
    "\tb1 = np.random.randn(n_h,1)*0.01\n",
    "\tw2 = np.random.randn(train_y.shape[0],n_h)*0.01/np.sqrt(train_y.shape[0])\n",
    "\tb2 = np.random.randn(train_y.shape[0],1)*0.01\n",
    "\n",
    "\tnum_iters = 10\n",
    "\tlearning_rate = 0.1\n",
    "\tm = (1/train_y.shape[1])\n",
    "\tfor i in range(num_iters):\n",
    "\t\t#print(w1.shape,w2.shape,b1.shape,b2.shape) # checkind dimensions\n",
    "\n",
    "\t\t###### FORWARD PROPAGATION #######\n",
    "\n",
    "\t\tz1 = np.dot(w1,train_x.T) + b1 # linear transform\n",
    "\t\tA1 = np.maximum(z1,0.001*z1) # ReLu Activation or maybe we can use leaky ReLu \n",
    "\t\tz2 = np.dot(w2,A1) + b2\n",
    "\t\tA2 = (1/(1+np.exp(-z2))) # sigmoid activation to get y hat \n",
    "\n",
    "\t\t\n",
    "\t\t#print(np.log(abs(1-A2)))\n",
    "\t\t#cost = -(1/m)*np.sum(np.dot(train_y,np.log(A2).T)+np.dot(1-train_y,np.log(1-A2).T))\n",
    "\t\tcost = log_loss(train_y,A2) # this is throwing some error, \n",
    "\t\t\t\t\t\t\t\t\t # no patiance to workaround, will write own loss function\n",
    "\t\t#print(z2)\n",
    "\t\t#print(\"Iteration %i, cost %.4f\"%(i,cost))\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\t###### \tBACKWARD PROPAGATION #######\n",
    "\n",
    "\t\t#dA2 = train_y/A2 + (1-train_y)/(1-A2)\n",
    "\n",
    "\t\tdA2 = - (np.divide(train_y, A2) - np.divide(1 - train_y, 1 - A2))\n",
    "\t\t#print(dA2)\n",
    "\t\tdz2 = (dA2*(z2*(1-z2))) # deriative of sigmoid \n",
    "\n",
    "\t\tdw2 = (np.dot(dz2,A1.T))/m\n",
    "\n",
    "\t\t# print(w2.shape,dw2.shape) # checking fwd bwd param dims\n",
    "\n",
    "\t\tdb2 = np.sum(dz2, axis = 1, keepdims = True) / m\n",
    "\n",
    "\t\tdA1 = np.dot(w2.T,dz2)\n",
    "\n",
    "\t\t\n",
    "\t\tdz1 = (dA1 ) #relu derivative (modified, ReLu is not differentiable at 0 )\n",
    "\n",
    "\t\tdw1 = np.dot(dz1,train_x) / m\n",
    "\n",
    "\t\tdb1 = np.sum(dz1, axis = 1, keepdims = True) / m\n",
    "\t\t#print(w1.shape,dw1.shape, b1.shape, db1.shape) # checking fwd bwd param dims\n",
    "\t\t\n",
    "\t\t##### UPDATING PARAMETERS ######\n",
    "\n",
    "\t\tw1 = w1 - learning_rate * dw1\n",
    "\t\tb1 = b1 - learning_rate * db1\n",
    "\t\tw2 = w2 - learning_rate * dw2\n",
    "\t\tb2 = b2 - learning_rate * db2\n",
    "\t\tcost2 = -(1/m)*np.sum(np.dot(train_y,np.log(A2).T))\n",
    "\t\t#print(\"Iteration %i, cost2 %.4f\"%(i,cost2))\n",
    "\n",
    "def call_function(x):\n",
    "\tdata, features =load('bc.csv')\n",
    "\t\"\"\" FUNCTION CALLS \"\"\"\n",
    "\tfunction = str(x)\n",
    "\t\n",
    "\tif function == \"LR\":\n",
    "\t\tLogReg(data,features)\n",
    "\telif function == \"NN\":\n",
    "\t\t#hidden_unit_size = [5 , 10 , 15 , 20 , 25 , 50 , 100 , 200 , 500, 1000]\n",
    "\t\t#hidden_unit_size = [5 , 10 , 15 , 20 , 25 , 26, 27, 28, 29, 30]\n",
    "\t\tarr_res=[]\n",
    "\t\t#parameters = two_layer_model(data, features,100, learning_rate = 0.0050, num_iterations = 30000, print_cost = True)\n",
    "\t\tstart = time.time()\n",
    "\t\tfor i in range(50,100):\n",
    "\t\t\tdata, features =load('bc.csv')\n",
    "\t\t\tprint('\\n',i)\n",
    "\t\t\tparameters = two_layer_model(data, features,2*i, learning_rate = 0.0035, num_iterations = 30000, print_cost = False)\n",
    "\t\t\tarr_res.append(parameters)\n",
    "\t\tend = time.time()\n",
    "\n",
    "\t\tprint(\"Time taken = %.4f\"%(end-start))\n",
    "\t\tplt.plot([i+1 for i in range(1,51)],arr_res,'bo')\n",
    "\t\tplt.ylabel(\"Test Accuracy\")\n",
    "\t\tplt.xlabel(\"Hidden Unit Size\")\n",
    "\t\tplt.show()\n",
    "\t\t\n",
    "\telif function == \"GMM\":\t\n",
    "\t\tprint(\"\\nAccuracy with Random Forest Classifier using GMM = %.4f\\n\"%(gmm(data,features)))\n",
    "\telif function == \"RFC\":\t\n",
    "\t\tprint(\"\\nAccuracy with Random Forest Classifier = .%4f\\n\"%(RandomForests(data , features)))\n",
    "\telif function == \"SVM\":\t\n",
    "\t\tkernels = ['rbf','linear','poly','sigmoid']\n",
    "\t\tLogReg(data,features)\n",
    "\t\tfor i in kernels:\t\n",
    "\t\t\tstart = time.time()\n",
    "\t\t\tprint(\"\\nAccuracy using SVM with \",i,\":\",SVM(data,features,i)*100)\n",
    "\t\t\tend = time.time()\n",
    "\t\t\tprint(\"Time taken for \",i,\" = %.4f seconds\"%(end-start))\n",
    "\telif function == \"DNN\":\n",
    "\t\tlayers_dims = [19, 100,100,100, 1]\n",
    "\t\tL_layer_model(data, features, layers_dims, learning_rate = 0.05, num_iterations = 15000, print_cost = True)\t\t\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # LR = Logistic Regression\n",
    "    # SVM = SVM\n",
    "    # NN = one hidden layer NN\n",
    "    # DNN = explicit number of hidden layers with L-1 ReLu and final Sigmoid layer\n",
    "    # RFC = Random Forest\n",
    "    # GMM = Random Forest with Gaussian Mixture\n",
    "\t#call_function(\"LR\")\n",
    "\tcall_function(\"NN\")\n",
    "\tcall_function(\"DNN\")\n",
    "\tcall_function(\"SVM\")\n",
    "\t#call_function(\"RFC\")\n",
    "\t#call_function(\"GMM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
